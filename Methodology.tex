\chapter {Methodology}

\section{Model Development}
\begin{enumerate}
    \item Conduct a comprehensive analysis of existing models for PoW and PoS blockchains. Select a state-of-the-art model that employs a bottom-up approach, making it easier to incorporate new factors into it. Provide a comprehensive explanation of its components.

    \item Acquire a deep understanding of the interplay of microscopic factors and their macroscopic effects in Ethereum PoS. With this knowledge, consider the limited 'post-merge' data available and identify 2-3 factors that can be integrated into the base model.

    \item Analyse data and literature relating these factors to electricity consumption in various contexts. Adhering to the principles of Rule-Based Mathematical Modelling outlined in REF, develop equations related to PoS Ethereum, either by adapting existing equations to the given context or through modelling observed behaviours.

    \item Incorporate these equations into the base model. Estimate the network shares of users with different hardware, client, and node configurations, and assign weights parts of the equation where possible.

    \item Determine the contemporary metrics (e.g., gas fees, transaction count, etc.) required to implement the model proposed along with competing models. Implement all models using the same metrics to produce easily comparable values (like energy consumption per transaction) to facilitate the evaluation of the model's results.

\end{enumerate}

\section {Evaluation Metrics}

\subsection{Quantitative}
\label{MethoologyErrorQuant}
The aim of a validation metric is to be able to assess the predictive capability of a mathematical model \cite{Kat2012ValidationError}. Metrics for comparison will be obtained by implementing other similar mathematical models. Most relative-error measures rely on true observed values to compare with a predicted value. However, since all models estimate the energy consumption of Ethereum, and there is no true value, selecting an appropriate quantitative error measure is challenging. 

Alternatively, the magnitude error, which compares the relative orders of magnitude between two functions, could be used as a means of validating the results obtained. To calculate the magnitude error using \eref{eqn:ErrorMeasureEqn}, estimates from the only experimental model (CCRI base model) will be used as the true values $\boldsymbol{\mathrm{m}}$ while estimates from our 'Model-A' will replace $\boldsymbol{\mathrm{p}}$ \cite{RussellErrorMeasure}. The suggested upper bound for a result being acceptable is $\boldsymbol{\epsilon_\mathrm{rme} \leq 0.2}$.

\begin{align}
\label{eqn:ErrorMeasureEqn}
    &\boldsymbol{\epsilon_\mathrm{rme} = \mathrm{sign(rme)} * \log_{10} (1 + |\mathrm{rme}|)}
    &\boldsymbol{ \mathrm{rme} = \mathrm{\frac{\mathrm{\sum\limits_{i=1}^{N} p_{i}^{2}} - \mathrm{\sum\limits_{i=1}^{N} m_{i}^{2}}}{\sqrt{\mathrm{\sum\limits_{i=1}^{N} p_{i}^{2}} * \mathrm{\sum\limits_{i=1}^{N} m_{i}^{2}}}}}}
\end{align}

% --------------------------------------------------------------------
\subsection{Qualitative}
\label{QualModelEvalMEthodology}
 It would be a near-impossible task to successfully simulate the model proposed in this paper using a computer program without losing the main characteristics that are leveraged to build upon the existing CCRI model, such as the non-linear increase in electricity consumption when running additional validators on a single node. The model can be evaluated using some of the model verification techniques mentioned in a chapter \cite{Al-Aomar2015ModelTechniques} from the book 'Process Simulations'.

\textbf{1. Thorough Examination of Model Inputs :}

During the construction of the model, this will be done by solely relying on actual data rather than theories to ensure the credibility of this model. When verifying the model, input values for each part of the model will be obtained only from scientific sources where possible. Otherwise, anecdotal data from multiple sources must be averaged in order to be used in verifying the model. Validation of model inputs is done by making sure that they are:
\begin{enumerate}
    \item Correct
    \item Relevant to the real-world system being modelled
    \item Being used in the model similar to the way they would be used by the real-world system being modelled
\end{enumerate}  


\textbf{2. Detailed Documentation of Model Logic :}
Thorough documentation on every design decision made during the construction of the model must be stated. Every decision made in this paper will be intuitively reinforced by domain-specific knowledge or data that was collected in a scientific manner. This is critical to the credibility of this model and helps any future work that may be undertaken on the model.

Additionally, any assumptions made during the model formulation must be highlighted using bold formatting.


\textbf{3. Thorough Examination of Model Outputs :}

The model outputs must be checked for 'reasonableness under a variety of input parameters' \cite{Al-Aomar2015ModelTechniques}. Any discrepancies between Model-A and other models must be justified in the discussion section.   


\section {Data Gathering}

The singular source of scientific data available in this field is the CCRI study \cite{CryptoCarbonRatingsInstitute2022TheNetwork}. Apart from using those results, data sources ranged from blockchain crawlers used to obtain metrics such as transaction counts to anecdotal and non-scientific data from Reddit and Discord communities, with users reporting on personal experiences and measurements. See Appendix A.

The CCRI \cite{Ccri-apiOverview} and Etherscan \cite{EtherscanProvider} APIs will be used to pursue a data-driven approach to modelling. Most of the publicly available CCRI indices have annualised values for various daily estimates and will be divided by 365 to obtain true daily values. 

\section {Modelling The Energy Consumption Using Domain Knowledge}

*Define everything in your modelling world, what your definition of everything is

We care about the power coming from the grid. The AC 'At-Wall'. We gather estimations for the recommended configuration of hardware for Ethereum nodes running validator clients. 

Also decide on which way of data gathering is better. Prepare a table of online users claiming their power consumption. Also, estimate the power consumption of the recommended configuration of hardware through manufacturer websites. This is then compared to the data from the \cite{CryptoCarbonRatingsInstitute2022TheNetwork} report actually running a single validator node to check if this bottom-up hardware estimation approach is valid. 

Knowing the fact that increasing the number of validator clients on a single machine increases the power consumption logarithmically, we apply this assumption to the CCRI equation. We also need to account for power inefficiency of the computer by adding a factor to this equation. The report does not mention the power supply or mainboard used.

Also need to add the syncing energy into the equation as it is not a short process. Need to model this, depending on the data and add it to the equation. (possibly for every combination of CL and EL client)


\section {Data-driven Approach To Modelling The Energy Consumption}

\section {Modelling The Carbon Emissions }
* Advice was to make the model, logically make the equations, justify each assumption etc, then gather some data for it, apply the data see what output you get. Then implement other's models using this data. Finally compare results, say why your model was/was not accurate.

\section {Implementing The Model}

% ------------------------------------------------------------------

\section {Project Management}
*must be done right here, not later

Couldn't use CCRI API as it wasn't ready yet. Has to scrape it from the website from the network section.

Couldn't use API - may have affected the accuracy of data, could've been live data, more precise data

\section{Critical Evaluation}

\subsection{Project Management Evaluation}

Many different approaches to modelling were tried during the course of the project. Some include sensitivity analysis to check which parameters affect the overall electricity consumption the most when using the PoS consensus protocol \cite{MarionAnModelling}. Some data-driven modelling techniques explored included time series analysis and logistic regression \cite{IbanezTheExpansion} however, the 'The Merge' is a very recent event, and it was hard to obtain any meaningful data on it.  ***talk about the risk table

The original plan of this project was to develop blockchain-based solutions for modelling drug supply chains, but it underwent multiple revisions. This was among the foreseen risks in opting for a blockchain-related topic as it is a relatively new technology. This risk was mitigated by following the pre-planned risk mitigation strategy found in in /ref**** in the appendix.

I learnt that it is simple to understand a simplified model of a complex system; however, to be the one modelling it requires absolute subject-matter expertise. Deep knowledge of cryptocurrencies as well as the Ethereum protocol specifically, had to be acquired in order to expand to the pre-existing models meaningfully. 